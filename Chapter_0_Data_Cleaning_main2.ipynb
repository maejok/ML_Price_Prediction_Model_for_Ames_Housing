{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Chapter 1 DataCleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first session deals with data cleaning, EDA and builing a simplistic model that can be used for predicting the sale price of houses in Ames, IOWA. Here we try to understand the dataset and get familiar with the methodology for developing an efficient model.\n",
    "\n",
    "The next session contains a report that contains  the detailed analysis, interpretation, and information for the models. We will do a cross-validation and data splitting where the original data set is split into two data sets: the training set and the validation set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "There are two data sets included in the data folder: `Ames_Housing_Price_Data.csv` and `Ames_Real_Estate_Data.csv`.\n",
    "\n",
    "The `Ames_Housing_Price_Data.csv` set contains $81$ data columns, including the key feature **SalePrice** which will be used as the target of the predictive/descriptive modeling. **PID** refers to the land parcel ID, which can merged on the *MapRefNo* column of the **Ames Accessor Data** (`Ames_Real_Estate_Data.csv`) to find the property address. Using a free service, such as **geopy**, we can find the long-lat coordinates of the houses.\n",
    "\n",
    "The columns of the data are mostly attributes associated with the land and the houses. There are size related attributes, quality and condition attributes, house attachment attributes, etc.\n",
    "\n",
    "To establish a foundation for your team's data analytics, we offer some insights on the house sizes vs. prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "The instructors' notes state:\n",
    "\n",
    "> **Five observations** that an instructor may wish to remove from the data set before giving it to students (a plot of SALE PRICE versus GR LIV AREA will quickly indicate these\n",
    "points). Three of them are true **outliers** (Partial Sales that likely donâ€™t represent actual market values) and two of them are simply unusual sales (very large houses priced\n",
    "relatively appropriately). I would **recommend removing any houses with more than\n",
    "3700 square feet** from the data set (which eliminates these five unusual observations)\n",
    "before assigning it to students.\n",
    "\n",
    "To apply a more \"rigorous\" approach, outlier detection is conducted with a so-called Isolation Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the datasets and the libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "import statistics as stats\n",
    "realEstate = pd.read_csv(\"Ames_Real_Estate_Data.csv\")\n",
    "realEstate = realEstate[['MapRefNo','Prop_Addr','MA_Zip1']]\n",
    "geocode_data =pd.read_csv(\"geocode_data.csv\")\n",
    "\n",
    "#Linear Models\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "\n",
    "\n",
    "#Kernel Ridge Regression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "\n",
    "#Gradient Boosting Machines\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Support Vector Machines\n",
    "from sklearn import svm\n",
    "\n",
    "#Linear Regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "#Make Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#Robust Scaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "\n",
    "housing = pd.read_csv('Ames_HousePrice.csv', index_col=0)\n",
    "housing = housing[housing.GrLivArea<3700]\n",
    "from scipy import stats\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = housing.groupby(\"YrSold\").mean()\n",
    "plt.scatter(year[['GrLivArea']], year[\"SalePrice\"])\n",
    "year\n",
    "list(map(lambda x,y: x/y, housing.groupby(\"YrSold\")[\"SalePrice\"].mean(), housing.groupby(\"YrSold\")[\"GrLivArea\"].mean() ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"Street\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.Condition1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.merge(housing, geocode_data.iloc[:,1:6], how='left', left_on='PID', right_on =\"PID\")\n",
    "housing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing[\"exp_OverallQual\"]= housing[\"OverallQual\"].apply(lambda x: np.exp(x))\n",
    "qual_related = housing.filter(regex='Qual$|Cond$').fillna(\"TA\")\n",
    "\n",
    "qual_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing.groupby(['YrSold','MoSold'])['SalePrice'].aggregate(np.mean).plot(kind='bar'\n",
    "                                                                              \n",
    "                                                                             ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qual_related.GarageCond.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values vith TA\n",
    "qual_related.fillna(\"TA\", inplace=True)\n",
    "def Rating(t):\n",
    "    if t ==\"Ex\": return  7\n",
    "    elif t == \"Gd\": return 5\n",
    "    elif t == \"TA\": return 3\n",
    "    elif t == \"Fa\": return 2.5\n",
    "    elif t == \"Po\": return 1\n",
    "    else: return 0\n",
    "for ele in qual_related.iloc[:,2:]:\n",
    "    \n",
    "    housing[ele]=qual_related[ele].map(Rating)\n",
    "    qual_related[ele]=housing[ele]\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values vith TA\n",
    "\n",
    "def yearidx(t):\n",
    "    if t ==2006: return  1.186\n",
    "    elif t == 2007: return 1.208\n",
    "    elif t == 2008: return 1.198\n",
    "    elif t == 2009: return 1.208\n",
    "    elif t == 2010: return 1.19\n",
    "    else: return 1.2\n",
    "\n",
    "    \n",
    "housing[\"GrLivArea_year\"]=housing[\"YrSold\"].map(yearidx)*housing[\"GrLivArea\"]\n",
    "housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UpSampling the Street labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.Street.value_counts()\n",
    "def Ratio(t):\n",
    "    if t == 'Pave': return 1.0\n",
    "   \n",
    "    else: return 180.0\n",
    "# the returned values must be integers   \n",
    "ratios = housing['Street'].map(Ratio)\n",
    "index_repeat = housing.index.repeat(ratios)\n",
    "index_repeat = pd.Series(index_repeat, name='repeat')\n",
    "index_repeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"Street\"].value_counts()\n",
    "housing[\"Street\"] =housing[\"Street\"].apply(lambda x: 1 if x==\"Pave\" else 0)\n",
    "housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "housing = housing.loc[index_repeat].Street.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.merge(index_repeat, housing, how='left', left_on = \"repeat\", right_on=housing.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ratio2(t):\n",
    "    if t ==\"Normal\": return  1.0\n",
    "    elif t == \"Partial\": return 4\n",
    "    elif t == \"Alloca\": return 5\n",
    "    elif t == \"Abnormal\": return 6\n",
    "    elif t == \"Family\": return 12\n",
    "    else: return 100\n",
    "\n",
    "ratios = housing['SaleCondition'].map(Ratio2)\n",
    "index_repeat = housing.index.repeat(ratios)\n",
    "index_repeat = pd.Series(index_repeat, name='repeat1')\n",
    "index_repeat\n",
    "housing = pd.merge(index_repeat, housing, how='left', left_on = \"repeat1\", right_on=housing.index)\n",
    "housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnd(t):\n",
    "    if t ==\"PConc\": return  1\n",
    "    elif t == \"CBlock\": return 0\n",
    "    else: return -0.5\n",
    "\n",
    "housing['Foundation'] = housing['Foundation'].map(fnd)\n",
    "    \n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"GarageType\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grg(t):\n",
    "    if t ==(\"Attchd\" or \"Builtin\") : return  1\n",
    "    else: return 0\n",
    "    -0.5\n",
    "\n",
    "housing['GarageType'] = housing['GarageType'].map(grg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def scond(t):\n",
    "    if t ==(\"Partial\") :\n",
    "        return  1\n",
    "    elif t == \"Normal\":\n",
    "        return 0\n",
    "    else: return -1\n",
    "\n",
    "housing['SaleCondition'] = housing['SaleCondition'].map(scond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.SalePrice"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def stype(t):\n",
    "    if t ==(\"CWD\") :\n",
    "        return  2\n",
    "    elif t ==(\"New\") :\n",
    "        return  1\n",
    "    elif t == \"Con\":\n",
    "        return 0.7\n",
    "    if t ==(\"ConLD\") :\n",
    "        return  -1\n",
    "    else: return 0\n",
    "\n",
    "housing['SaleType'] = housing['SaleType'].map(stype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"MasVnrType\"] =np.where(housing[\"MasVnrType\"]==(\"BrkCmn\" or \"Stone\"),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"RoofStyle\"] = np.where(housing[\"RoofStyle\"] == \"Hip\",1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique PID #s\n",
    "uni = housing.PID.unique()\n",
    "uni.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How does the price vary by neighbourhood\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "\n",
    "housing.boxplot(column ='SalePrice', by = 'Neighborhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging 2.5Unf values into 1Story\n",
    "housing['HouseStyle'].replace('2.5Unf', '1Story', inplace=True)\n",
    "# merging 2.5Fin to 2Story\n",
    "housing['HouseStyle'].replace('2.5Fin', '2Story', inplace=True)\n",
    "# merging 1.5Unf values into 1.5Fin\n",
    "housing['HouseStyle'].replace('1.5Unf', '1.5Fin', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.HouseStyle.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding and Dummyfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the averge price by neighborhood\n",
    "dummy = housing.groupby([\"Neighborhood\",\"YrSold\"])[[\"SalePrice\"]].mean()\n",
    "dummy.rename(columns = {\"SalePrice\":\"Price_by_hood\"}, inplace =True)\n",
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "housing = pd.merge(housing, dummy, how='left', on=['Neighborhood', 'Neighborhood'])\n",
    "housing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get the averge price by neighborhood\n",
    "dummy2 = housing.groupby([\"MoSold\", \"YrSold\"])[[\"SalePrice\"]].mean()\n",
    "dummy2.rename(columns = {\"SalePrice\":\"Price_by_month\"}, inplace =True)\n",
    "\n",
    "housing = pd.merge(housing, dummy2, how='left', left_on=['MoSold', 'YrSold'],right_on=['MoSold', 'YrSold'])\n",
    "housing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing.SaleType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We trim the outliers from the list\n",
    "#housing = housing\n",
    "#leng = len(housing)\n",
    "#print(leng)\n",
    "#housing[\"Gradient\"] = (housing.SalePrice-15000)/(housing.GrLivArea)\n",
    "\n",
    "#housing=housing.sort_values(by=\"Gradient\")[(housing.sort_values(by=\"Gradient\")[\"Gradient\"]>30) & (housing.sort_values(by=\"Gradient\")[\"Gradient\"]<220)]\n",
    "#housing[\"Gradient2\"] = (housing.SalePrice)/(housing.GrLivArea-1600.01) \n",
    "#housing=housing.sort_values(by=\"Gradient2\")[ (housing.sort_values(by=\"Gradient2\")[\"Gradient2\"]>250)|(housing.sort_values(by=\"Gradient2\")[\"Gradient2\"]<0)]\n",
    "#housing[\"Gradient3\"] = (housing.SalePrice -100000)/(housing.TotalBsmtSF +1) \n",
    "#housing=housing.sort_values(by=\"Gradient3\")[ (housing.sort_values(by=\"Gradient3\")[\"Gradient3\"]<200)]\n",
    "#housing[\"Gradient4\"] = (housing.SalePrice)/(housing.TotalBsmtSF-1200.01) \n",
    "#housing=housing.sort_values(by=\"Gradient4\")[ (housing.sort_values(by=\"Gradient4\")[\"Gradient4\"]>300000/1300)|(housing.sort_values(by=\"Gradient4\")[\"Gradient4\"]<0)]\n",
    "\n",
    "#housing\n",
    "#leng2 = len(housing)\n",
    "#outlier_pct = 100*(leng-leng2)/leng\n",
    "#outlier_pct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.PavedDrive = np.where(housing.PavedDrive==\"N\", 0,1)\n",
    "housing.CentralAir = np.where(housing.CentralAir==\"N\", 0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df): \n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_pct = 100 * df.isnull().sum() / len(df)\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_pct], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        return mis_val_table_ren_columns.sort_values(by= \"Missing Values\")[mis_val_table_ren_columns[\"Missing Values\"]>10] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_table(housing)[\"Missing Values\"].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing=housing.drop([\"MiscFeature\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[housing.columns[housing.isnull().any()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Proximity to various Conditions\"\n",
    "\n",
    "The columns *Condition 1* and *Condition 2* have the same realizations and can be regarded as \"tags\" given to a house indicating the nearby presence of a) a major street, b) a railroad, or c) a park.\n",
    "\n",
    "The default tag \"Norm\" (implying no \"condition\") is given to 86% of the houses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"Condition1\"] = housing[\"Condition1\"].apply(lambda x: 0 if x ==\"Norm\" else 1)\n",
    "housing[\"Condition2\"] = housing[\"Condition2\"].apply(lambda x: 0 if x ==\"Norm\" else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the NA values which aren't NAs to different values to work better with the data set\n",
    "medl = housing.LotFrontage.median()\n",
    "medm = housing.MasVnrArea.median()\n",
    "housing.Alley = housing.Alley.fillna(\"No Alley Access\")\n",
    "housing.LotFrontage = housing.LotFrontage.fillna(medl)\n",
    "housing.MasVnrArea = housing.MasVnrArea.fillna(medm)\n",
    "housing.MasVnrType = housing.MasVnrType.fillna('None')\n",
    "housing.BsmtQual = housing.BsmtQual.fillna(\"No Basement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "housing.PoolQC = housing.PoolQC.fillna(0)\n",
    "housing.PoolQC=np.where(housing.PoolQC==0, 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NA with the right values\n",
    "housing.BsmtCond = housing.BsmtCond.fillna(\"No Basement\")\n",
    "housing.BsmtExposure = housing.BsmtExposure.fillna(\"No Basement\")\n",
    "housing.BsmtFinType1 = housing.BsmtFinType1.fillna(\"No Basement\")\n",
    "housing.BsmtFinType2 = housing.BsmtFinType2.fillna(\"No Basement\")\n",
    "housing.FireplaceQu = housing.FireplaceQu.fillna(\"No Fireplace\")\n",
    "housing.GarageType = housing.GarageType.fillna(\"No Garage\")\n",
    "housing.GarageFinish = housing.GarageFinish.fillna(\"No Garage\")\n",
    "housing.GarageQual = housing.GarageQual.fillna(\"No Garage\")\n",
    "housing.GarageCond = housing.GarageCond.fillna(\"No Garage\")\n",
    "housing.Fence = housing.Fence.fillna(\"No Fence\")\n",
    "housing.Electrical = housing.Electrical.fillna(\"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext(t):\n",
    "    if t in  ['PreCast',  'ImStucc', 'CemntBd']:\n",
    "        return 1\n",
    "    elif t in ['AsphShn', 'AsbShng', 'CBlock']:\n",
    "        return -1\n",
    "    else: \n",
    "        return 0\n",
    "housing['Exterior1st'] = housing['Exterior1st'].map(ext)\n",
    "housing['Exterior2nd'] = housing['Exterior2nd'].map(ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(len(housing[\"Exterior1st\"])):\n",
    "    if housing[\"Exterior1st\"][i] in  ['PreCast',  'ImStucc', 'CemntBd']:\n",
    "        housing[\"Exterior1st\"][i] =1\n",
    "    elif housing[\"Exterior1st\"][i] in ['AsphShn', 'AsbShng', 'CBlock']:\n",
    "        housing[\"Exterior1st\"][i] =-1\n",
    "    else: \n",
    "        housing[\"Exterior1st\"][i] =0\n",
    "for i in range(len(housing[\"Exterior2nd\"])):\n",
    "    if housing[\"Exterior1st\"][i] in  ['PreCast',  'ImStucc', 'CemntBd']:\n",
    "        housing[\"Exterior1st\"][i] =1\n",
    "    elif housing[\"Exterior1st\"][i] in ['AsphShn', 'AsbShng', 'CBlock']:\n",
    "        housing[\"Exterior1st\"][i] =-1\n",
    "    else: \n",
    "        housing[\"Exterior1st\"][i] =0    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify the two townhouse types into one.\n",
    "housing[\"BldgType\"] = housing[\"BldgType\"].apply(\n",
    "    lambda x: \"Twnhs\" if x in (\"TwnhsE\", \"TwnhsI\") else x\n",
    ")\n",
    "# Unify the two kinds of 2-family homes.\n",
    "housing[\"BldgType\"] = housing[\"BldgType\"].apply(\n",
    "    lambda x: \"2Fam\" if x in (\"2FmCon\", \"Duplx\") else x\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#imputing KNN #imputing KNN \n",
    "\n",
    "from fancyimpute  import KNN\n",
    "# calling the KNN class\n",
    "knn_imputer = KNN()\n",
    "# imputing the missing value with knn imputer\n",
    "\n",
    "housing[['LotFrontage','MasVnrArea',\"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"TotalBsmtSF\",\"GarageArea\",\"long\",\"lat\",\"dist\",\"income\",\"BsmtFullBath\",\"BsmtHalfBath\",\"GarageCars\",\"GarageYrBlt\"]] = knn_imputer.fit_transform(housing[['LotFrontage','MasVnrArea',\"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"TotalBsmtSF\",\"GarageArea\",\"long\",\"lat\",\"dist\",\"income\",\"BsmtFullBath\",\"BsmtHalfBath\",\"GarageCars\",\"GarageYrBlt\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "med1 = housing.BsmtFinSF1.median()\n",
    "med2 = housing.BsmtFinSF2.median()\n",
    "medf = housing.BsmtUnfSF.median()\n",
    "medt = housing.TotalBsmtSF.median()\n",
    "meda = housing.GarageArea.median()\n",
    "medlon =housing.long.median()\n",
    "medlat = housing.lat.median()\n",
    "medist = housing.dist.median()\n",
    "medinc = housing.income.median()\n",
    "\n",
    "housing.BsmtFinSF1 = housing.BsmtFinSF1.fillna(med1)\n",
    "housing.BsmtFinSF2 = housing.BsmtFinSF2.fillna(med2)\n",
    "housing.BsmtUnfSF = housing.BsmtUnfSF.fillna(medf)\n",
    "housing.TotalBsmtSF = housing.TotalBsmtSF.fillna(medt)\n",
    "housing.GarageArea = housing.GarageArea.fillna(meda)\n",
    "housing.long = housing.long.fillna(medlon)\n",
    "housing.lat = housing.lat.fillna(medlat)\n",
    "housing.dist = housing.dist.fillna(medist)\n",
    "housing.income = housing.income.fillna(medinc)\n",
    "\n",
    "housing.BsmtFullBath = housing.BsmtFullBath.fillna(0.0)\n",
    "housing.BsmtHalfBath = housing.BsmtHalfBath.fillna(0.0)\n",
    "housing.GarageCars = housing.GarageCars.fillna(0.0)\n",
    "\n",
    "housing.GarageYrBlt = np.where(housing.GarageYrBlt.notnull(),housing.GarageYrBlt, housing.YearBuilt)\n",
    "\n",
    "housing.TotalBsmtSF = np.where(housing.TotalBsmtSF<20,800, housing.TotalBsmtSF)\n",
    "housing.BsmtFinSF1 = np.where(housing.BsmtFinSF1<20,800, housing.BsmtFinSF1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We covert the year to age and take the squareroot to normalise the values\n",
    "housing.YearBuilt = np.sqrt(2010 - housing.YearBuilt)\n",
    "housing.GarageYrBlt = np.sqrt(2010 - housing.GarageYrBlt)\n",
    "housing.YrSold = np.sqrt(2010 -housing.YrSold)\n",
    "housing.YearRemodAdd = np.sqrt(2010 -housing.YearRemodAdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.YearBuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of new column combining full and half bathrooms into one\n",
    "bathrm = (housing['FullBath'] + housing['BsmtFullBath'] +\n",
    "(housing['HalfBath']*0.5) + (housing['BsmtHalfBath']*0.5))\n",
    "housing['bathrm_cnt'] = bathrm\n",
    "\n",
    "# Creation of new column combining deck/porch-related sq footage into one\n",
    "patioSF = (housing['WoodDeckSF'] + housing['OpenPorchSF']+ housing['EnclosedPorch'] + \n",
    "           housing['3SsnPorch'] + housing['ScreenPorch'])\n",
    "housing['patioSF'] = patioSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(housing.SalePrice, hist = False, kde = True,\n",
    "            kde_kws = {'shade': True, 'linewidth': 2})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"SalePrice\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the log function to make the data normal\n",
    "plt.hist(np.log(housing.SalePrice+1), bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log(housing.SalePrice+1), hist = False, kde = True,\n",
    "            kde_kws = {'shade': True, 'linewidth': 2})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(housing[\"SalePrice\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the different types of foundations\n",
    "#print(housing.Foundation.value_counts())\n",
    "#sns.countplot(housing.Foundation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Keep the numerical data to the left and categorical data to the right.\n",
    "# Visualise the proportion of each categorical labels\n",
    "categorical_data=[]\n",
    "housing_new =pd.DataFrame()\n",
    "#print(len(housing_new))\n",
    "housing_new[\"SalePrice\"]=housing[\"SalePrice\"]\n",
    "for ele in housing.columns:\n",
    "    if np.dtype(housing[ele])== \"int64\" or np.dtype(housing[ele])==\"float64\":\n",
    "        housing_new[ele] = housing[ele]\n",
    "        print(len(housing_new))\n",
    "    else:\n",
    "        categorical_data.append(ele)\n",
    "        sns.countplot(housing[ele])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in categorical_data:\n",
    "    print(name, ': number of values', len(housing[name].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in categorical_data:\n",
    "    housing_new[ele] = housing[ele]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the dummies of each categorical Data.\n",
    "for ele in categorical_data:\n",
    "    # Converting type of columns to category\n",
    "    housing_new=pd.get_dummies(housing_new, prefix=\"{}_\".format(ele), \n",
    "                            columns=[ele], \n",
    "                            drop_first=True)\n",
    "    \n",
    "\n",
    "housing_new#=housing_new.drop([\"repeat\",\"repeat_x\", \"repeat_y\"], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from itertools import combinations\n",
    "# Get all combinations of [\n",
    "comb = combinations(housingimp[lst_53], 50)\n",
    "\n",
    "lst=[]\n",
    "scores=[]\n",
    "# Print the obtained combinations\n",
    "for i in list(comb):\n",
    "    ols = LinearRegression()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(housingimp[list(i)], housing_new.iloc[:,0], test_size=0.5, random_state=0)\n",
    "    #lst.append(list(i))\n",
    "    ols.fit(X_train, y_train)\n",
    "    lst.append(list(i))\n",
    "    scores.append(ols.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations\n",
    " \n",
    "# Get all combinations of according to the best contributions in increasing the R^2\n",
    "# The process creates a partail ording among the predictors where A rel B if A is Subset of B and R2A <=R2B\n",
    "# The time complexity of this process is n* nC1=n**2 where n is the number of columns\n",
    "fnlst =[]\n",
    "cscores =[]\n",
    "for ele in range(1,len(housing_new.columns),1):\n",
    "    \n",
    "    comb = combinations(housing_new.iloc[:,1:].columns.difference(fnlst), 1)\n",
    "\n",
    "    lst=[]\n",
    "    scores=[]\n",
    "    \n",
    "    # Print the obtained combinations\n",
    "    for i in list(comb):\n",
    "        ols = LinearRegression()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(housing_new[fnlst+list(i)], housing_new.iloc[:,0], test_size=0.5, random_state=0)\n",
    "        #lst.append(list(i))\n",
    "        ols.fit(X_train, y_train)\n",
    "        lst.append(list(i))\n",
    "        scores.append(ols.score(X_train, y_train))\n",
    "    cscores.append(pd.Series(scores).max())\n",
    "    fnlst =fnlst+lst[pd.Series(scores)[pd.Series(scores)==pd.Series(scores).max()].index[0]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ols = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing_new[fnlst], housing_new.iloc[:,0], test_size=0.5, random_state=0)\n",
    "\n",
    "ols.fit(X_train, y_train)\n",
    "print('-'*50)\n",
    "\n",
    "print(\"R^2 for train set: %f\" %ols.score(X_train, y_train))\n",
    "print(\"R^2 for test set: %f\" %ols.score(X_test, y_test))\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(range(len(cscores)), cscores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
